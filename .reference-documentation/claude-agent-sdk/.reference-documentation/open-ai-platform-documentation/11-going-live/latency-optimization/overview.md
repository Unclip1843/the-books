# OpenAI Platform - Latency Optimization Overview

**Source:** https://platform.openai.com/docs/guides/latency
**Fetched:** 2025-10-11

## Overview

Reduce response latency for better user experience.

---

## Optimization Techniques

### 1. Streaming
Enable token-by-token responses

### 2. Model Selection
- gpt-4o-mini: Faster responses
- gpt-4o: Better quality, slightly slower

### 3. Predicted Outputs
Provide expected output structure for faster generation

### 4. Prompt Optimization
- Shorter prompts
- Clear instructions
- Reduced context

### 5. Infrastructure
- Regional endpoints
- CDN for static content
- Connection pooling

---

## Next Steps

- [Predicted Outputs](./predicted-outputs.md)
- [Priority Processing](./priority-processing.md)

---

**Source:** https://platform.openai.com/docs/guides/latency
